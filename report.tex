\documentclass[letterpaper]{article} 

 %\linespread{1.5}
\title{Predicting Gene ``Mapk1" in Mice}

\author{
  D'Azevedo, Gloria\\
  \texttt{gad87@cornell.edu}
  \and
  Yadav, Pihu\\
  \texttt{py82@cornell.edu}
}
\date{December 2, 2016}

\begin{document}
\maketitle

\section{Executive Summary}
%This needs to be written last

\section{Introduction and Problem Definition}
The goal of this analysis is to take a gene expression data set for a mouse and develop a model to predict the amount of the gene ``Mapk1".  In general, gene analysis is important because they are an indicator for the current and future health issues for the organism as well as the organism's offspring.  However, the procedures to decompose the gene expressions can be expensive and can take
a long time, so a model that requires few predictors to predict the value of a certain gene is crucial to accurate and early diagnosis 
for a potential disease.  In addition, experiments can be done to assess the effects from the presence or absence of specific genes to an organism so cures for these diseases can be devloped and doctors know exactly what genes to target to cure their patients.\\
%
The data set that is used to develop a model is very small.  There are only 40 different gene expressions, with the responses from 24 genes
in each.  There are no missing values.  The responses are all real numbers, ranging from -2.5 to 2.  Model types to investigate include linear regression with least squares, regularized linear regression, and K-Nearest-Neighbors.  In addition, resampling methods such as boostrapping and cross-validation will be extremely useful as there is so little data.  These methods and techniques are generally quite interpretable and the robustness can be tested using the resampling methods mentioned above.
%
\section{Model Development}

\subsection{Best Subset Using Linear Models}
There are 22 genes that can be leveraged to predict the response for the ``Mapk1" gene so one of the implemented models is the best subset selection algorithm.  In this algorithm, all possible $2^r$ linear models are fit to the data using least squares where $r$ is the number of predictors (in this case, $r=22$).  Then, the algorithm returns the best set of predictors for a model of size $r$, for each $r$.  Generally, this algorithm is very computationally intensive but there are only $n=40$ data points so each iteration runs quite quickly on an average computer.  The downside of this algorithm for this data set is that there are only 40 data points, so splitting it further into training and test sets would yield poor estimates of the model for each iteration and the test set is still quite small.  In addition, there are more steps to fit each of the best predictor subsets to the data again to find the coefficients for the linear model of that size and to evaluate the training error and/or test error.

\subsection{Forward-Backward Model Selection with Bayesain Information Criterion (BIC)}

\section{Results and Conclusions}

\section{Next Steps}
In the future, if data is collected for more mice and there are more gene expressions to analyze, other methods such as K-Nearest-
Neighbors (KNN) can be implemented which is a robust, unsupervised machine learning technique.  Currently, as there are only 40 
samples, the number of points that have k nearst neighbors is at most 40-k, assuming that the whole data set is used as a training 
set and none of it is used to evaluate the model and estimate test error.  Currently if the algorithm is implemented, the 
model is grossly overfit on the training data, which yields a low training error, which does not imply a low test error for future samples.

\end{document}